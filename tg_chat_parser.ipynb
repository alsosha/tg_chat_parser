{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bece506",
   "metadata": {},
   "source": [
    "# Инструмент для парсинга тг-чата"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2648291",
   "metadata": {},
   "source": [
    "В данном случае под парсингом подразумевается работы с выгруженным архивом тг-чата в формате json. Получить архив можно следующим образом:\n",
    "\n",
    "1) Устанавливаем десктопную версию тг по ссылке: https://desktop.telegram.org/\n",
    "2) После установки логинимся и открываем нужный нам чат\n",
    "3) Кликаем на три точки в верхнем правом углу чата\n",
    "4) В меню выбираем \"Экспорт истории чата\"\n",
    "5) После этого в окошке выбираем настройки экспорта: типы данных для выгрузки и временной период. Если вас интересует только текст чата, то смысла отмечать галочкой для скачивания изображения, видео, стикеры, аудио и т.д. нет\n",
    "6) Запускаем процесс экспорта и ждем. Процесс не быстрый, но окно можно свернуть и делать что-то параллельно\n",
    "7) Наконец, получаем заветный архив тг-чата\n",
    "\n",
    "Внутри архива будет много различных папок и html-файлы \"messages.html\", \"messages2.html\" и т.д. В контексте анализа текстов сообщения нас интересуют именно эти html-файлы, остальное не нужно. Копируем эти файлы в папку, в которой расположен ipynb-файл этого инструмента и начинаем анализ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e4ca4",
   "metadata": {},
   "source": [
    "Если в процессе работы у тебя возникнут предложения по улучшению инструмента, можно написать мне в тг: @esthesuntik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b76011",
   "metadata": {},
   "source": [
    "### Импортируем библиотеки и модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80075049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import codecs\n",
    "import docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ecf0e-3e35-4e1f-bb41-b78407a77f65",
   "metadata": {},
   "source": [
    "### Поиск сообщений конкретного автора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e9927",
   "metadata": {},
   "source": [
    "Ниже написана функция, с помощью которой происходит обработка json-файла и извлечение текстов сообщений автора. В ней ничего не нужно менять, можно просто изучить в связке с одним из html-файлов \"messages\". Затем запустить остальные ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8830f6c9-c1ed-4d6f-980f-41a228f28965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# на вход функция принимает название анализируемого файла и имя / ник автора, сообщения которого мы ищем\n",
    "def messages_finder(file_name, search_name):\n",
    "\n",
    "    # считываем json-файл\n",
    "    file = codecs.open(file_name, 'r', 'utf-8')\n",
    "    html = file.read()\n",
    "\n",
    "    soup = BS(html, \"lxml\")\n",
    "\n",
    "    # получаем все сообщения из чата в формате списка\n",
    "    all_messages = soup.find_all('div', class_ = 'body')\n",
    "\n",
    "    author_messages = []\n",
    "\n",
    "    # в цикле ищем сообщения с нужным автором\n",
    "    for i in range(len(all_messages)):\n",
    "        author = all_messages[i].find('div', class_ = 'from_name')\n",
    "        \n",
    "        if author != None:\n",
    "            if author.text.strip() == search_name:\n",
    "                author_messages.append(all_messages[i])\n",
    "        else:\n",
    "            n = i-1\n",
    "            author = all_messages[n].find('div', class_ = 'from_name')\n",
    "            \n",
    "            while author == None:\n",
    "                n = n-1\n",
    "                author = all_messages[n].find('div', class_ = 'from_name')\n",
    "    \n",
    "            if author.text.strip() == search_name:\n",
    "                author_messages.append(all_messages[i])\n",
    "\n",
    "    \n",
    "    # из кода сообщений нужного автора собираем тексты в список\n",
    "    author_messages_texts = []\n",
    "\n",
    "    for message in author_messages:\n",
    "        forward_check = message.find('div', class_ = 'forwarded')\n",
    "\n",
    "        if forward_check == None:\n",
    "            message_text = message.find('div', class_ = 'text')\n",
    "        \n",
    "            if message_text != None:\n",
    "                author_messages_texts.append(message_text.text)\n",
    "\n",
    "    # функция возвращает список с текстами сообщений\n",
    "    return author_messages_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33c61d",
   "metadata": {},
   "source": [
    "В ячейку ниже нужно вписать все названия html-файлов из архива (которые мы в начале скопировали в папку к инструменту).\n",
    "\n",
    "Решение костыльное и в будущем будет исправлено на более удобный вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9137cc6-461f-4c3e-99e6-b2dd5d822d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['messages.html', 'messages2.html', 'messages3.html', 'messages4.html', 'messages5.html', 'messages6.html',\n",
    "         'messages7.html', 'messages8.html', 'messages9.html', 'messages10.html', 'messages11.html', 'messages12.html',\n",
    "         'messages13.html', 'messages14.html', 'messages15.html']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70146b20",
   "metadata": {},
   "source": [
    "В переменную ниже нужно вписать реальное имя пользователя (как он отображается у вас в тг).\n",
    "\n",
    "Важно, чтобы в начале и в конце имени не было лишних пробелов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c825535",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_name = 'Имя пользователя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009eb2ee-7934-4b12-aa15-562a297364f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогоняем через функцию все html-файлы тг-архива\n",
    "\n",
    "messages_texts = []\n",
    "all_messages_count = 0\n",
    "\n",
    "for file in files:\n",
    "    file_messages = messages_finder(file, search_name)\n",
    "    messages_texts += file_messages\n",
    "    \n",
    "    all_messages_count += len(file_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542fb6f",
   "metadata": {},
   "source": [
    "В ячейке ниже 'file_name' замените на удобное название файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e81db-3ae2-4bd1-a0f9-af7827ec2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cохраняем сообщения в docx-файл\n",
    "\n",
    "document = docx.Document()\n",
    "\n",
    "for message_text in messages_texts:\n",
    "\n",
    "    document.add_paragraph(message_text)\n",
    "\n",
    "document.save('file_name.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e0632-d2a5-4ed6-ac88-a2f26d9c79e3",
   "metadata": {},
   "source": [
    "### Парсинг сообщений всех авторов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2422bf7",
   "metadata": {},
   "source": [
    "Функция ниже является упрощенной версией алогритма по поиску сообщения конкретного автора. Тут мы не фильтруем поиск по конкретному имени и собираем все тексты сообщений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156028a5-5aa9-4671-8dc8-0d1dbb5b198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_parser(file_name):\n",
    "    file = codecs.open(file_name, 'r', 'utf-8')\n",
    "    html = file.read()\n",
    "\n",
    "    soup = BS(html, \"lxml\")\n",
    "\n",
    "    all_messages = soup.find_all('div', class_ = 'text')\n",
    "\n",
    "    all_messages_texts = []\n",
    "\n",
    "    for message in all_messages:\n",
    "        forward_check = message.find('div', class_ = 'forwarded')\n",
    "\n",
    "        if forward_check == None:\n",
    "            all_messages_texts.append(message.text)\n",
    "\n",
    "    return(all_messages_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d346896",
   "metadata": {},
   "source": [
    "В ячейку ниже нужно вписать все названия html-файлов из архива (которые мы в начале скопировали в папку к инструменту).\n",
    "\n",
    "Решение костыльное и в будущем будет исправлено на более удобный вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b740cc7-ab2b-47c5-965c-c0c107885fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['messages.html', 'messages2.html', 'messages3.html', 'messages4.html', 'messages5.html', 'messages6.html',\n",
    "         'messages7.html', 'messages8.html', 'messages9.html', 'messages10.html', 'messages11.html', 'messages12.html',\n",
    "         'messages13.html', 'messages14.html', 'messages15.html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fc0f1-ed70-4c4f-b75b-fe81b5683975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогоняем через функцию все html-файлы тг-архива\n",
    "\n",
    "messages_texts = []\n",
    "\n",
    "for file in files:\n",
    "    file_messages = messages_parser(file)\n",
    "    messages_texts += file_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563eace",
   "metadata": {},
   "source": [
    "В ячейке ниже 'file_name' замените на удобное название файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186c0db-8322-42d2-8385-faaa4b154e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = docx.Document()\n",
    "\n",
    "for message_text in messages_texts:\n",
    "\n",
    "    document.add_paragraph(message_text)\n",
    "\n",
    "document.save('file_name.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7949d",
   "metadata": {},
   "source": [
    "Ура, тексты собраны! Теперь можно обработать их. Например, с помощью другого моего инструмента по анализу текста: [ссылка на код](https://github.com/alsosha/text_analysis/blob/main/text_analysis.ipynb)\n",
    "\n",
    "А потом можно сгенерировать облако слов: [ссылка на код](https://github.com/alsosha/word_cloud_generator/blob/main/word_cloud_generator.ipynb). Ну или построить любые другие графики. Удачи :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
